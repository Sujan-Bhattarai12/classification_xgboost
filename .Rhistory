tic()
tree_tune <- tune_grid(
xgboost_tree_spec,
eel_recipe,
resamples = cv_set,
grid = tree_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
tree_tune
#set all warnings and messages false
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
#load all libraries requiref for xgboost
library(tidymodels)
library(xgboost)
library(tictoc)
library(vip)
library(readr)
library(dplyr)
library(purrr)
library(ggplot2)
library(ranger)
library(yardstick)
library(workflows)
library(recipes)
library(modeldata)
library(parsnip)
library(dials)
#download the data from github using direct github link
training_data <- read_csv("https://raw.githubusercontent.com/MaRo406/eds-232-machine-learning/main/data/eel.model.data.csv")
evaluation_data <- read_csv("https://raw.githubusercontent.com/MaRo406/eds-232-machine-learning/main/data/eel.eval.data.csv")
#take a look at the data, look at na values and nuermic, categorical columns
glimpse(training_data)
#conver the Angaus column to a factor
training_data$Angaus <- as.factor(training_data$Angaus)
# Create a recipe to prepare your data for the XGBoost model
eel_recipe <- recipe(Angaus ~ ., data = training_data) %>%
step_naomit(all_predictors()) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes())
#split to 80-20 train and test set
set.seed(123)
eel_split <- initial_split(training_data, prop = 0.8, strata = Angaus)
train <- training(eel_split)
test <-  testing(eel_split)
#use 10 fold cross validation to resample the training set
cv_set <- vfold_cv(train, v = 10, strata = Angaus)
#Instantiate the xgboost model
xgboost_spec <- boost_tree(
learn_rate = tune())%>%
set_engine("xgboost") %>%
set_mode("classification")
#Set up a grid to tune your model by using a range of learning rate parameter values\
learn_rate_grid <- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))
#Set up a grid to tune your model by using a range of learning rate parameter values\
learn_rate_grid <- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))
# tune the model with the learning rate grid
tic()
learn_rate_tune <- tune_grid(
xgboost_spec,
eel_recipe,
resamples = cv_set,
grid = learn_rate_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
#select the best model
best_learn_rate <- learn_rate_tune %>%
select_best(metric = "roc_auc")
best_learn_rate[[1]]
best_learn_rate[[1]]
# tune only tree parameters
xgboost_tree_spec <- boost_tree(
trees = tune(),
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
#tuning grid for the tree in the xgboost model
tree_grid <- grid_latin_hypercube(
trees(),
size = 20)
#tuning grid for the tree in the xgboost model
tree_grid <- grid_latin_hypercube(
trees(),
size = 20)
#use the tuning grid to tune the tree parameters
tic()
tree_tune <- tune_grid(
xgboost_tree_spec,
eel_recipe,
resamples = cv_set,
grid = tree_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
#select the best model
best_tree <- tree_tune %>%
select_best(metric = "roc_auc")
best_tree
# tune only stochastic parameters
xgboost_stoch_spec <- boost_tree(
mtry = tune(),
col_sample_rate = tune(),
sample_size = tune(),
trees = best_tree[[1]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
# tune only stochastic parameters
xgboost_stoch_spec <- boost_tree(
mtry = tune(),
colsample_bytree = tune(),
sample_size = tune(),
trees = best_tree[[1]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
# tune only stochastic parameters
xgboost_stoch_spec <- boost_tree(
mtry = tune(),
sample_size = tune(),
trees = best_tree[[1]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
# tune only stochastic parameters
xgboost_stoch_spec <- boost_tree(
mtry = tune(),
lambda = tune(),
sample_size = tune(),
trees = best_tree[[1]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
# tune only stochastic parameters
xgboost_stoch_spec <- boost_tree(
mtry = tune(),
sample_size = tune(),
trees = best_tree[[1]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(
mtry(),
sample_size(),
size = 20)
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(
mtry(),
size = 20)
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(
mtry = tune(),
size = 20)
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube()
#Set up a tuning grid. This time use grid_latin_hypercube() to get a representative sampling of the parameter space
tree_grid <- grid_latin_hypercube(
trees() %>% finalize(mtry = NULL),
size = 20)
#set all warnings and messages false
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
#load all libraries requiref for xgboost
library(tidymodels)
library(xgboost)
library(tictoc)
library(vip)
library(readr)
library(dplyr)
library(purrr)
library(ggplot2)
library(ranger)
library(yardstick)
library(workflows)
library(recipes)
library(modeldata)
library(parsnip)
library(dials)
#download the data from github using direct github link
training_data <- read_csv("https://raw.githubusercontent.com/MaRo406/eds-232-machine-learning/main/data/eel.model.data.csv")
evaluation_data <- read_csv("https://raw.githubusercontent.com/MaRo406/eds-232-machine-learning/main/data/eel.eval.data.csv")
#take a look at the data, look at na values and nuermic, categorical columns
glimpse(training_data)
#conver the Angaus column to a factor
training_data$Angaus <- as.factor(training_data$Angaus)
# Create a recipe to prepare your data for the XGBoost model
eel_recipe <- recipe(Angaus ~ ., data = training_data) %>%
step_naomit(all_predictors()) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_center(all_predictors(), -all_outcomes()) %>%
step_scale(all_predictors(), -all_outcomes())
#split to 80-20 train and test set
set.seed(123)
eel_split <- initial_split(training_data, prop = 0.8, strata = Angaus)
train <- training(eel_split)
test <-  testing(eel_split)
#use 10 fold cross validation to resample the training set
cv_set <- vfold_cv(train, v = 10, strata = Angaus)
#Instantiate the xgboost model
xgboost_spec <- boost_tree(
learn_rate = tune())%>%
set_engine("xgboost") %>%
set_mode("classification")
#Set up a grid to tune your model by using a range of learning rate parameter values\
learn_rate_grid <- expand.grid(learn_rate = seq(0.0001, 0.3, length.out = 30))
# tune the model with the learning rate grid
Sys.time()
learn_rate_tune <- tune_grid(
xgboost_spec,
eel_recipe,
resamples = cv_set,
grid = learn_rate_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
Sys.time()
#select the best model
best_learn_rate <- learn_rate_tune %>%
select_best(metric = "roc_auc")
# show the performance for each learning rate with the best model based on estimate vlaue
learn_rate_tune %>%
collect_metrics() %>%
filter(.metric == "roc_auc") %>%
ggplot(aes(x = learn_rate, y = mean)) +
geom_point() +
geom_line() +
labs(title = "Learning Rate Tuning",
x = "Learning Rate",
y = "ROC AUC")
# tune only tree parameters
xgboost_tree_spec <- boost_tree(
trees = tune(),
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
#Set up a tuning grid. This time use grid_latin_hypercube() to get a representative sampling of the parameter space
tree_grid <- grid_latin_hypercube(
trees() %>% finalize(mtry = NULL),
size = 20)
#use the tuning grid to tune the tree parameters
tree_tune <- tune_grid(
xgboost_tree_spec,
eel_recipe,
resamples = cv_set,
grid = tree_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
#select the best model
best_tree <- tree_tune %>%
select_best(metric = "roc_auc")
# plot the table instead of the plot
# tune only stochastic parameters
xgboost_stoch_spec <- boost_tree(
min_n = tune(),
tree_depth = tune(),
trees = best_tree[[1]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(min_n(), tree_depth(), size = 20)
#use the tuning grid to tune the stochastic parameters
stoch_tune <- tune_grid(
xgboost_stoch_spec,
eel_recipe,
resamples = cv_set,
grid = stoch_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
#select the best model
best_stoch <- stoch_tune %>%
select_best(metric = "roc_auc")
#finalize the model with best parameters
final_xgboost <- boost_tree(
trees = best_tree[[1]],
min_n = best_stoch[[1]],
tree_depth = best_stoch[[2]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
#fit the model on the data
fit(final_xgboost, Angaus ~ ., train)
# use last fit to predict on the test data
eel_predictions <- last_fit(final_xgboost, Angaus ~ .,
eel_split)
#show the predictions
eel_predictions$.predictions
#get the accuracy of the model
accuracy(eel_predictions$.predictions, truth = test$Angaus)
# tune only stochastic parameters
xgboost_stoch_spec <- boost_tree(
mtry = tune(),
min_n = tune(),
tree_depth = tune(),
trees = best_tree[[1]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
# tune only stochastic parameters
xgboost_stoch_spec <- boost_tree(
mtry = tune(),
min_n = tune(),
sample_size = tune(),
tree_depth = tune(),
trees = best_tree[[1]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(min_n(), tree_depth(), size = 20)
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(mtry(),
min_n(),
tree_depth(),
size = 20)
# finalize mtry range based on the number of predictors
mtry_finalized <- finalize(mtry(), baked_train)
# finalize mtry range based on the number of predictors
mtry_finalized <- finalize(mtry(), train)
mtry_finalized
# finalize mtry range based on the number of predictors
mtry_finalized <- finalize(mtry(), train)
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(mtry(),
min_n(),
tree_depth(),
size = 20)
# finalize mtry range based on the number of predictors
mtry_finalized <- finalize(mtry(), train)
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(mtry_finalized,
min_n(),
tree_depth(),
size = 20)
#use the tuning grid to tune the stochastic parameters
stoch_tune <- tune_grid(
xgboost_stoch_spec,
eel_recipe,
resamples = cv_set,
grid = stoch_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
# finalize mtry range based on the number of predictors
mtry_finalized <- finalize(mtry(), train)
#tuning grid for the stochastic parameters in the xgboost model
stoch_grid <- grid_latin_hypercube(mtry_finalized,
sample_size = sample_prop(),
min_n(),
tree_depth(),
size = 20)
#use the tuning grid to tune the stochastic parameters
stoch_tune <- tune_grid(
xgboost_stoch_spec,
eel_recipe,
resamples = cv_set,
grid = stoch_grid,
metrics = metric_set(roc_auc),
control = control_grid(save_pred = TRUE)
)
#select the best model
best_stoch <- stoch_tune %>%
select_best(metric = "roc_auc")
best_stoch
#finalize the model with best parameters
final_xgboost <- boost_tree(
trees = best_tree[[1]],
min_n = best_stoch[[1]],
sample_size = best_stoch[[4]],
tree_depth = best_stoch[[2]],
learn_rate = best_learn_rate[[1]]) %>%
set_engine("xgboost") %>%
set_mode("classification")
#fit the model on the data
fit(final_xgboost, Angaus ~ ., train)
# use last fit to predict on the test data
eel_predictions <- last_fit(final_xgboost, Angaus ~ .,
eel_split)
#show the predictions
eel_predictions$.predictions
#get the accuracy of the model
accuracy(eel_predictions$.predictions, truth = test$Angaus)
truth = test$Angaus
test$Angaus
eel_predictions$.predictions
#show the predictions
eel_predictions$.predictions
#show the predictions
eel_predictions$.predictions[2]
#show the predictions
eel_predictions$.predictions[[2]]
# use last fit to predict on the test data
eel_predictions <- last_fit(final_xgboost,
Angaus ~ .,
eel_split)
#show the predictions
eel_predictions$.predictions
eel_predictions
#fit the model on the data
final_fit <- fit(final_xgboost, Angaus ~ ., train)
# use last fit to predict on the test data
eel_predictions <- last_fit(final_xgboost,
Angaus ~ .,
eel_split)
#show the predictions
eel_predictions$.predictions
#eel_preductions has two output, chose only .pred_class
eel_predictions$.pred_class
#eel_preductions has two output, chose only .pred_class
eel_predictions$.predictions$.pred_class
#eel_preductions has two output, chose only .pred_class
eel_predictions$.predictions
#get the accuracy of the model
accuracy(eel_predictions$.predictions, truth = test$Angaus)
class(eel_predictions)
# use last fit to predict on the test data
eel_predictions <- last_fit(final_xgboost,
Angaus ~ .,
eel_split) %>%
collect_predictions()
eel_predictions
#get the accuracy of the model
accuracy(eel_predictions$.pred_class, truth = test$Angaus)
#get the accuracy of the model
accuracy(eel_predictions$.pred_class, truth = test$Angaus)
#get the accuracy of the model
accuracy(eel_predictions$.pred_class, truth = eel_predictions$.Angaus)
eel_predictions
#calculate the aaccuracy based on two column .pred_class and Angaus
accuracy(eel_predictions, truth = Angaus, estimate = .pred_class)
#plot the confusion matrix
conf_mat <- eel_predictions %>%
conf_mat(truth = Angaus, estimate = .pred_class)
conf_mat
#use the yardstick package to evaluate the model
eel_predictions %>%
metrics(truth = Angaus, estimate = .pred_class)
#use the yardstick package to evaluate the model
eel_predictions %>%
metrics(truth = Angaus, estimate = .pred_class)
#plot the confusion matrix
eel_predictions %>%
conf_mat(truth = Angaus, estimate = .pred_class)
##go to the test set and add all 1 values in anguas to calculate how many anguas were there
test %>%
filter(Angaus == 1) %>%
nrow()
##go to the test set and add all 1 values in anguas to calculate how many anguas were there
test %>%
filter(Angaus == 0) %>%
nrow()
conf_mat
##go to the test set and add all 1 values in anguas to calculate how many anguas were there
test %>%
filter(Angaus == 0) %>%
nrow()
# fit with the evaluation data
final_fit <- fit(final_xgboost, Angaus ~ ., training_data)
final_fit
#check the accuracy of the model
final_fit %>%
predict(evaluation_data) %>%
bind_cols(evaluation_data) %>%
metrics(truth = Angaus, estimate = .pred_class)
# fit with the evaluation data
final_fit <- fit(final_xgboost, Angaus ~ ., evaluation_data)
evaluation_data
# fit with the evaluation data
final_fit <- fit(final_xgboost, Angaus_obs ~ ., evaluation_data)
#change the Angaus column to factor
evaluation_data$Angaus_obs <- as.factor(evaluation_data$Angaus_obs)
# fit with the evaluation data
final_fit <- fit(final_xgboost, Angaus_obs ~ ., evaluation_data)
#check the accuracy of the model
final_fit %>%
predict(evaluation_data) %>%
bind_cols(evaluation_data) %>%
metrics(truth = Angaus, estimate = .pred_class)
#check the accuracy of the model
final_fit %>%
predict(evaluation_data) %>%
bind_cols(evaluation_data) %>%
metrics(truth = Angaus_obs, estimate = .pred_class)
#count the number of non anguas in the evaluation data
evaluation_data %>%
filter(Angaus_obs == 0) %>%
nrow()
#count the number of non anguas in the evaluation data
evaluation_data %>%
filter(Angaus_obs == 1) %>%
nrow()
#plot confusion matrix
conf_mat <- final_fit %>%
predict(evaluation_data) %>%
bind_cols(evaluation_data) %>%
conf_mat(truth = Angaus_obs, estimate = .pred_class)
conf_mat
#use vip to compare variable importance
final_fit %>%
pull_workflow_fit() %>%
vip::vip(num_features = 10)
#use vip to plot the variable importance
final_fit %>%
pull_workflow_fit() %>%
vip::vip(num_features = 10)
#use vip to plot the variable importance
final_fit %>%
vip::vip(num_features = 10)
